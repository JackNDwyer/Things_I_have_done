{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import some Python dependencies\n",
    "\n",
    "#bring in relevant libraries\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import httplib, urllib, json, locale\n",
    "from urlparse import urlparse\n",
    "import operator\n",
    "import bson\n",
    "from collections import OrderedDict\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "import csv\n",
    "import json\n",
    "import urllib2\n",
    "from instagram import InstagramAPI\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "merchant_ids = []\n",
    "top_posts = []\n",
    "df_list= []\n",
    "#connecting to our db\n",
    "connection = MongoClient(host = '')\n",
    "db=connection.heroku_ckbhgr9b\n",
    "merchant = db['Merchants']\n",
    "ACCESS_TOKEN = ''\n",
    "for merchants in merchant.find():\n",
    "     merchant_ids.append(str(merchants['_id']))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "for MERCHANT_ID in merchant_ids:\n",
    "    #eventually we'll want this to be brought in externally from mongo\n",
    "\n",
    "    #object_id = 'ObjectId(\\\"' + MERCHANT_ID + '\\\")'\n",
    "    doc1 = []\n",
    "\n",
    "    for doc in merchant.find({'_id':ObjectId(MERCHANT_ID)}):\n",
    "         doc1.append(doc)\n",
    "    try:\n",
    "        access_token = doc1[0]['pos_access_token']\n",
    "\n",
    "        record=db['Reports']\n",
    "\n",
    "        access_token = str(access_token)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#access_token = ''\n",
    "\n",
    "#the below functions are described in detail here: http://facebook-sdk.readthedocs.io/en/latest/api.html\n",
    "def request_until_succeed(url):\n",
    "    req = urllib2.Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try: \n",
    "            response = urllib2.urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception, e:\n",
    "            print e\n",
    "            time.sleep(5)\n",
    "\n",
    "            print \"Error for URL %s: %s\" % (url, datetime.datetime.now())\n",
    "\n",
    "            print \"Error for URL %s: %s\" % (url, datetime.datetime.now())\n",
    "    return response.read()\n",
    "\n",
    "def getFacebookPageFeedData(page_id, access_token, num_statuses):\n",
    "\n",
    "    # construct the URL string\n",
    "    base = \"https://graph.facebook.com\"\n",
    "    node = \"/\" + page_id + \"/feed\" \n",
    "    parameters = \"/?fields=message,link,created_time,type,name,id,likes.limit(20).summary(true),comments.limit(20).summary(true),shares&limit=%s&access_token=%s\" % (num_statuses, access_token)\n",
    "    url = base + node + parameters\n",
    "\n",
    "    # retrieve data\n",
    "    data = json.loads(request_until_succeed(url))\n",
    "\n",
    "    return data\n",
    "\n",
    "def processFacebookPageFeedStatus(status):\n",
    "\n",
    "    # The status is now a Python dictionary, so for top-level items,\n",
    "    # we can simply call the key.\n",
    "\n",
    "    # Additionally, some items may not always exist,\n",
    "    # so must check for existence first\n",
    "\n",
    "    status_id = status['id']\n",
    "    status_message = '' if 'message' not in status.keys() else status['message'].encode('utf-8')\n",
    "    link_name = '' if 'name' not in status.keys() else status['name'].encode('utf-8')\n",
    "    status_type = status['type']\n",
    "    status_link = '' if 'link' not in status.keys() else status['link']\n",
    "    # Time needs special care since a) it's in UTC and\n",
    "    # b) it's not easy to use in statistical programs.\n",
    "\n",
    "    status_published = datetime.datetime.strptime(status['created_time'],'%Y-%m-%dT%H:%M:%S+0000')\n",
    "    status_published = status_published + datetime.timedelta(hours=-5) # EST\n",
    "    status_published = status_published.strftime('%Y-%m-%d %H:%M:%S') # best time format for spreadsheet programs\n",
    "    \n",
    "\n",
    "\n",
    "    # Nested items require chaining dictionary keys.\n",
    "    comment_content = []\n",
    "    num_likes = 0 if 'likes' not in status.keys() else status['likes']['summary']['total_count']\n",
    "    num_comments = 0 if 'comments' not in status.keys() else status['comments']['summary']['total_count']\n",
    "    for i in range(len(status[\"comments\"][\"data\"])):\n",
    "        comment_content.append(status['comments']['data'][i]['message'])\n",
    "    #for i in len(num_comments):\n",
    "        #comment_content.append('' if 'comments' not in status.keys else status['comments'])\n",
    "    num_shares = 0 if 'shares' not in status.keys() else status['shares']['count']\n",
    "\n",
    "\n",
    "    return (status_id, status_message, link_name, status_type, status_link,\n",
    "           status_published, num_likes, num_comments, num_shares, comment_content)\n",
    "\n",
    "\n",
    "for merchants in merchant.find():\n",
    "     merchant_ids.append(str(merchants['_id']))\n",
    "\n",
    "for MERCHANT_ID in merchant_ids:\n",
    "    #eventually we'll want this to be brought in externally from mongo\n",
    "    record=db['Marketing']\n",
    "\n",
    "    for doc in merchant.find({'_id':ObjectId(MERCHANT_ID)}):            \n",
    "\n",
    "        try:\n",
    "            #if this part doesn't work, they likely don't have facebook setup. Therefore we use try except\n",
    "            page_id = str(doc['facebook_page_id'])\n",
    "            m_id = str(doc['merchant_id'])\n",
    "            name = str(doc['name'])\n",
    "            #access_token = str(doc['facebook_token'])\n",
    "            statuses = getFacebookPageFeedData(page_id, ACCESS_TOKEN, 30)['data']\n",
    "            #print statuses\n",
    "            comments = []\n",
    "            for comment in statuses:\n",
    "                #print comment\n",
    "                comments.append(processFacebookPageFeedStatus(comment))\n",
    "            \n",
    "            \n",
    "            df = pd.DataFrame(comments)\n",
    "            #setting column names\n",
    "            df.columns = ['post_id','message','type_of_post','content_category','link_associated','date','likes','comment_quant','shares', 'comment_content']\n",
    "            #sorting based on likes first, then comments\n",
    "            df = df.sort_values(['likes','comment_quant'], ascending=False).reset_index(drop=True)\n",
    "            #isolating only the columns we want\n",
    "            df_top_post_att = df[['message','content_category','link_associated', 'likes', 'comment_quant','comment_content']].head(5)\n",
    "            #taking only the top 5 entries\n",
    "            df_list.append(df_top_post_att)\n",
    "            #making a dictionary out of this\n",
    "            dict_top_posts = df_top_post_att.to_dict('records')\n",
    "            #append to our top posts list, just in case we need a list of all top posts from every client\n",
    "            top_posts.append(dict_top_posts)\n",
    "            #upload data to merchant collection of mongo\n",
    "            record.update_many({\n",
    "              'merchant_uid': MERCHANT_ID\n",
    "                },{\n",
    "                '$set': {\n",
    "                    'name':name,\n",
    "                    'id':MERCHANT_ID,\n",
    "                    'facebook_page_id':page_id,\n",
    "                    'merchant_id':m_id,\n",
    "                    'top_5_facebook_posts': dict_top_posts,\n",
    "                    'fb_business_account_id':'?',\n",
    "                    'instagram_acct_id':'?',\n",
    "                    'instgram_bus_acct_id':'?'\n",
    "                      }\n",
    "                }, upsert=True)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#insta account id\n",
    "#insta business account id\n",
    "#top 5 instagram post data [{{post text, post image/video, likes, comments[]}}]\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "comment_content_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
