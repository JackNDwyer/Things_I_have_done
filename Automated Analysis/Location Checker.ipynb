{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this script will find the revenue by location for the 24 hours before it was run\n",
    "\n",
    "\n",
    "#bring in relevant libraries\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import httplib, urllib, json, locale\n",
    "from urlparse import urlparse\n",
    "import operator\n",
    "import bson\n",
    "from collections import OrderedDict\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merchant_ids = []\n",
    "#connecting to our db\n",
    "connection = MongoClient(host =)\n",
    "db=\n",
    "merchant = db['Merchants']\n",
    "for merchants in merchant.find():\n",
    "     merchant_ids.append(str(merchants['_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [location, quantity, name, price]\n",
      "Index: []\n",
      "{'location': [], 'revenue': []}\n",
      "Empty DataFrame\n",
      "Columns: [location, quantity, name, price]\n",
      "Index: []\n",
      "{'location': [], 'revenue': []}\n",
      "Empty DataFrame\n",
      "Columns: [location, quantity, name, price]\n",
      "Index: []\n",
      "{'location': [], 'revenue': []}\n",
      "                name       location  quantity  price\n",
      "0           Combo #1  A4RYS03VV89MM      25.0  13.75\n",
      "1           Combo #2  A4RYS03VV89MM       1.0  13.75\n",
      "2           Combo #3  A4RYS03VV89MM      23.0  13.75\n",
      "3           Combo #4  A4RYS03VV89MM       1.0  11.75\n",
      "4      Dipping Sauce  A4RYS03VV89MM       4.0   0.50\n",
      "5              Drink  A4RYS03VV89MM       5.0   1.50\n",
      "6       French Fries  A4RYS03VV89MM       6.0   4.00\n",
      "7       French Fries  A4RYS03VV89MM       6.0   4.00\n",
      "8   Kimchi Ball 3pcs  A4RYS03VV89MM       4.0   6.50\n",
      "9       Lg 14pcs KFC  A4RYS03VV89MM       5.0  18.00\n",
      "10      Med 7pcs KFC  A4RYS03VV89MM      19.0  10.00\n",
      "11         Pr. Drink  A4RYS03VV89MM       2.0   2.00\n",
      "12       Sm 4pcs KFC  A4RYS03VV89MM      22.0   7.00\n",
      "13   Tofu Balls 3pcs  A4RYS03VV89MM       1.0   6.50\n",
      "{'location': [u'A4RYS03VV89MM'], 'revenue': [1213.5]}\n",
      "                                                 name       location  \\\n",
      "0                                             Avocado  AF8X744XSG5FE   \n",
      "1                                         Bag Charge   AF8X744XSG5FE   \n",
      "2                                    Boylan Diet Cola  AF8X744XSG5FE   \n",
      "3                                    Boylan Root Beer  AF8X744XSG5FE   \n",
      "4                                                CRAB  AF8X744XSG5FE   \n",
      "5                                      CRISPY CHICKEN  AF8X744XSG5FE   \n",
      "6                                                Cake  AF8X744XSG5FE   \n",
      "7                            Califia Black And White   AF8X744XSG5FE   \n",
      "8                                 Califia Triple Shot  AF8X744XSG5FE   \n",
      "9                                             Caprese  AF8X744XSG5FE   \n",
      "10                                       Cheese Slice  AF8X744XSG5FE   \n",
      "11                                 Chicken N Waffles   AF8X744XSG5FE   \n",
      "12                              Chinese Chicken Salad  AF8X744XSG5FE   \n",
      "13                                  Cocomels Sea Salt  AF8X744XSG5FE   \n",
      "14                                        Cream Donut  AF8X744XSG5FE   \n",
      "15                                          Croissant  AF8X744XSG5FE   \n",
      "16                                Curry Chicken Sando  AF8X744XSG5FE   \n",
      "17                                              DONUT  AF8X744XSG5FE   \n",
      "18                             Dirty Chips Sea Salted  AF8X744XSG5FE   \n",
      "19                   Dirty Potato Chips Mesquite BBQ   AF8X744XSG5FE   \n",
      "20                                 EGG SALAD Sandwich  AF8X744XSG5FE   \n",
      "21             Eat Pastry Gluten Free Choc Chip Dough  AF8X744XSG5FE   \n",
      "22                                    Egg Salad To Go  AF8X744XSG5FE   \n",
      "23                                               FISH  AF8X744XSG5FE   \n",
      "24                                             GF Pie  AF8X744XSG5FE   \n",
      "25                                       GRILL CHEESE  AF8X744XSG5FE   \n",
      "26                                         Gf Cupcake  AF8X744XSG5FE   \n",
      "27                             Harmless Coconut Water  AF8X744XSG5FE   \n",
      "28                                      Kale, Caesar!  AF8X744XSG5FE   \n",
      "29                           Kevita Coconut Probiotic  AF8X744XSG5FE   \n",
      "30               Louisville Vegan Jerky Carolina BBQ   AF8X744XSG5FE   \n",
      "31                           Luke's Organic BBQ Chips  AF8X744XSG5FE   \n",
      "32                                             MBALLS  AF8X744XSG5FE   \n",
      "33                                    Mac Salad To Go  AF8X744XSG5FE   \n",
      "34                                      Mamas Cookies  AF8X744XSG5FE   \n",
      "35                                               PB&J  AF8X744XSG5FE   \n",
      "36                       Pacific Org Choc Almond Milk  AF8X744XSG5FE   \n",
      "37                       Raw Juicery Bloody Brilliant  AF8X744XSG5FE   \n",
      "38                            Raw Juicery Boss' Tonic  AF8X744XSG5FE   \n",
      "39                             Raw Juicery Melon Ros√©  AF8X744XSG5FE   \n",
      "40                            Raw Juicery The Cleanup  AF8X744XSG5FE   \n",
      "41                                             SALAMI  AF8X744XSG5FE   \n",
      "42                                              SMASH  AF8X744XSG5FE   \n",
      "43                                          STEAK TIP  AF8X744XSG5FE   \n",
      "44             Saffron Road Falafel Crunchy Chickpeas  AF8X744XSG5FE   \n",
      "45                      Surf Sweets Sour Berry Bears   AF8X744XSG5FE   \n",
      "46                            Waiakea Volcanic Water   AF8X744XSG5FE   \n",
      "47           Wholesome Bakery Caramel Cookie Sandwich  AF8X744XSG5FE   \n",
      "48             Wholesome Bakery Kitchen Sink Cookies   AF8X744XSG5FE   \n",
      "49           Wholesome Bakery Oatmeal Cookie Sandwich  AF8X744XSG5FE   \n",
      "50  Wholesome Bakery Peanut Butter Choc Sea Salt C...  AF8X744XSG5FE   \n",
      "51                   Wholesome Bakery Snickerdoodle K  AF8X744XSG5FE   \n",
      "52                 Wholesome Bakery Thin Mint Cookies  AF8X744XSG5FE   \n",
      "\n",
      "    quantity  price  \n",
      "0        4.0   1.00  \n",
      "1        1.0   0.20  \n",
      "2        5.0   2.25  \n",
      "3        2.0   2.25  \n",
      "4        4.0  10.75  \n",
      "5       38.0  10.75  \n",
      "6        5.0   5.75  \n",
      "7        3.0   3.25  \n",
      "8        1.0   3.30  \n",
      "9        3.0  13.75  \n",
      "10       3.0   1.00  \n",
      "11       4.0   7.75  \n",
      "12       3.0   7.75  \n",
      "13       1.0   5.00  \n",
      "14      12.0   4.75  \n",
      "15       1.0   4.50  \n",
      "16       2.0  10.75  \n",
      "17      12.0   3.00  \n",
      "18       2.0   1.55  \n",
      "19       1.0   1.55  \n",
      "20       3.0  10.75  \n",
      "21       1.0   5.25  \n",
      "22       2.0   4.50  \n",
      "23       7.0  10.75  \n",
      "24       3.0   4.75  \n",
      "25      10.0   6.75  \n",
      "26       4.0   3.25  \n",
      "27       1.0   6.25  \n",
      "28       2.0   7.00  \n",
      "29       2.0   3.60  \n",
      "30       1.0   8.99  \n",
      "31       1.0   3.50  \n",
      "32      10.0  10.75  \n",
      "33       4.0   3.00  \n",
      "34       6.0   6.00  \n",
      "35       4.0   5.75  \n",
      "36       1.0   1.75  \n",
      "37       1.0   6.25  \n",
      "38       1.0   6.25  \n",
      "39       2.0   6.25  \n",
      "40       1.0   6.25  \n",
      "41       4.0  10.75  \n",
      "42       5.0  10.75  \n",
      "43       3.0  10.75  \n",
      "44       1.0   4.99  \n",
      "45       1.0   1.95  \n",
      "46       3.0   2.25  \n",
      "47       1.0   8.99  \n",
      "48       1.0   8.99  \n",
      "49       2.0   8.99  \n",
      "50       1.0   8.99  \n",
      "51       3.0   8.99  \n",
      "52       1.0   8.99  \n",
      "{'location': [u'AF8X744XSG5FE'], 'revenue': [1431.9400000000003]}\n",
      "                                                 name       location  \\\n",
      "0                                       Apero plateau  DRG6Z69RW5N00   \n",
      "1                                               Tapas  DRG6Z69RW5N00   \n",
      "2                                               Alpes  DRG6Z69RW5N00   \n",
      "3                                          Auvergnate  DRG6Z69RW5N00   \n",
      "4                                               Bacon  DRG6Z69RW5N00   \n",
      "5                                 Bandol Galantine GB  DRG6Z69RW5N00   \n",
      "6                                        By The Glass  DRG6Z69RW5N00   \n",
      "7                                         Californien  DRG6Z69RW5N00   \n",
      "8   Chateau De La Grangere- Saint Emilion Grand Cr...  DRG6Z69RW5N00   \n",
      "9                                     Chips Potatoes   DRG6Z69RW5N00   \n",
      "10                               Chocolate Croissant   DRG6Z69RW5N00   \n",
      "11                        Classic Sourdough Baguette   DRG6Z69RW5N00   \n",
      "12                                Clefs Des Legats GB  DRG6Z69RW5N00   \n",
      "13                                             Combo   DRG6Z69RW5N00   \n",
      "14                                         Croissant   DRG6Z69RW5N00   \n",
      "15                                         Diet Coke   DRG6Z69RW5N00   \n",
      "16                                       Duck Salami   DRG6Z69RW5N00   \n",
      "17                                              Extra  DRG6Z69RW5N00   \n",
      "18                                        Extra Fruit  DRG6Z69RW5N00   \n",
      "19                                         Extra Meat  DRG6Z69RW5N00   \n",
      "20                      Fabrique D√©lice - Cornichons   DRG6Z69RW5N00   \n",
      "21                                            Granola  DRG6Z69RW5N00   \n",
      "22                                            Italien  DRG6Z69RW5N00   \n",
      "23                                        Le Lyonnais  DRG6Z69RW5N00   \n",
      "24                                          Le Poitou  DRG6Z69RW5N00   \n",
      "25                                       Le Savoyard   DRG6Z69RW5N00   \n",
      "26                                        Lorina Pink  DRG6Z69RW5N00   \n",
      "27               Maison de Monaco - Black Mission Fig  DRG6Z69RW5N00   \n",
      "28                                             Mancha  DRG6Z69RW5N00   \n",
      "29                                            Oatmeal  DRG6Z69RW5N00   \n",
      "30                                           Occitane  DRG6Z69RW5N00   \n",
      "31                                          Orangina   DRG6Z69RW5N00   \n",
      "32                                           Parisien  DRG6Z69RW5N00   \n",
      "33                                            Perrier  DRG6Z69RW5N00   \n",
      "34                                Picpoul De Pinet GB  DRG6Z69RW5N00   \n",
      "35                                           Piemonte  DRG6Z69RW5N00   \n",
      "36                Pinot Noir Les M√ªriers Castelnau GB  DRG6Z69RW5N00   \n",
      "37                                          Provencal  DRG6Z69RW5N00   \n",
      "38                              Raincoast Fig & Olive  DRG6Z69RW5N00   \n",
      "39            Raincoast Oat & Cranberry (gluten Free)  DRG6Z69RW5N00   \n",
      "40                Rustic Bakery - Cookie- Meyer Lemon  DRG6Z69RW5N00   \n",
      "41                      Rustic Bakery - Cookie- Pecan  DRG6Z69RW5N00   \n",
      "42              Rustic Bakery - Flatbread - Olive Oil  DRG6Z69RW5N00   \n",
      "43                                        Side Salad   DRG6Z69RW5N00   \n",
      "44                                            Special  DRG6Z69RW5N00   \n",
      "45                                           Toulouse  DRG6Z69RW5N00   \n",
      "46                                  Volnay 1er Cru GB  DRG6Z69RW5N00   \n",
      "47                                             Water   DRG6Z69RW5N00   \n",
      "48                              Whole Wheat Baguette   DRG6Z69RW5N00   \n",
      "\n",
      "    quantity  price  \n",
      "0        1.0  19.00  \n",
      "1        1.0  19.00  \n",
      "2       16.0   8.99  \n",
      "3        3.0  10.99  \n",
      "4        1.0   2.00  \n",
      "5        1.0  21.95  \n",
      "6        3.0   8.00  \n",
      "7       24.0   9.99  \n",
      "8        2.0  29.95  \n",
      "9       13.0   1.50  \n",
      "10      10.0   2.95  \n",
      "11       1.0   4.99  \n",
      "12       1.0  14.95  \n",
      "13       1.0  29.00  \n",
      "14      10.0   2.70  \n",
      "15       1.0   2.00  \n",
      "16       3.0  15.99  \n",
      "17       3.0   0.50  \n",
      "18       1.0   2.00  \n",
      "19      10.0   2.00  \n",
      "20       1.0   4.99  \n",
      "21       3.0   4.00  \n",
      "22      18.0   9.99  \n",
      "23       3.0   6.99  \n",
      "24       6.0   6.50  \n",
      "25       5.0   5.99  \n",
      "26       1.0   2.50  \n",
      "27       3.0   5.99  \n",
      "28      26.0  10.99  \n",
      "29       1.0   4.00  \n",
      "30      11.0   9.99  \n",
      "31       2.0   2.50  \n",
      "32      11.0   9.99  \n",
      "33       2.0   2.50  \n",
      "34       1.0  13.95  \n",
      "35       1.0   8.99  \n",
      "36       1.0  12.95  \n",
      "37      15.0   8.99  \n",
      "38       2.0   6.99  \n",
      "39       1.0   6.99  \n",
      "40       1.0   4.99  \n",
      "41       1.0   4.99  \n",
      "42       3.0   6.99  \n",
      "43      33.0   3.00  \n",
      "44       5.0   9.99  \n",
      "45      19.0  10.99  \n",
      "46       1.0  86.95  \n",
      "47       8.0   1.00  \n",
      "48       1.0   4.99  \n",
      "{'location': [u'DRG6Z69RW5N00'], 'revenue': [2267.9100000000003]}\n",
      "Empty DataFrame\n",
      "Columns: [location, quantity, name, price]\n",
      "Index: []\n",
      "{'location': [], 'revenue': []}\n",
      "Empty DataFrame\n",
      "Columns: [location, quantity, name, price]\n",
      "Index: []\n",
      "{'location': [], 'revenue': []}\n"
     ]
    }
   ],
   "source": [
    "for MERCHANT_ID in merchant_ids:\n",
    "    #eventually we'll want this to be brought in externally from mongo\n",
    "    #object_id = 'ObjectId(\\\"' + MERCHANT_ID + '\\\")'\n",
    "    doc1 = []\n",
    "    for doc in merchant.find({'_id':ObjectId(MERCHANT_ID)}):\n",
    "         doc1.append(doc)\n",
    "    try:\n",
    "        access_token = doc1[0]['pos_access_token']\n",
    "        #print access_token\n",
    "        record=db['Reports']\n",
    "        locs = []\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    #cron = CronTab()\n",
    "    #job = cron.new(command='/usr/bin/echo')\n",
    "    #job.day.every(1)\n",
    "\n",
    "\n",
    "    #!/usr/bin/python\n",
    "    #\n",
    "    # Generating a payment report with the Square Connect API.\n",
    "\n",
    "\n",
    "\n",
    "    # Standard HTTP headers for every Connect API request\n",
    "    #access_token = 'sq0atp-TkDkbQjLEzdJixG3zo9Lqg'\n",
    "    request_headers = {'Authorization': 'Bearer ' + access_token,\n",
    "                       'Accept': 'application/json',\n",
    "                       'Content-Type': 'application/json'}\n",
    "\n",
    "    # The base URL for every Connect API request\n",
    "    connection = httplib.HTTPSConnection('connect.squareup.com')\n",
    "\n",
    "    # Uses the locale to format currency amounts correctly\n",
    "    locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "\n",
    "\n",
    "\n",
    "    # Helper function to convert cent-based money amounts to dollars and cents\n",
    "    def format_money(amount):\n",
    "      return locale.currency(amount / 100.)\n",
    "\n",
    "\n",
    "    # Obtains all of the business's location IDs. Each location has its own collection of payments.\n",
    "    def get_location_ids():\n",
    "      request_path = '/v1/me/locations'\n",
    "      connection.request('GET', request_path, '', request_headers)\n",
    "      response = connection.getresponse()\n",
    "\n",
    "      # Transform the JSON array of locations into a Python list\n",
    "      locations = json.loads(response.read())\n",
    "      location_ids = []\n",
    "      for location in locations:\n",
    "        location_ids.append(location['id'])\n",
    "        \n",
    "      return location_ids\n",
    "\n",
    "\n",
    "    # Downloads all of a business's payments\n",
    "    def get_payments_day(location_ids):\n",
    "\n",
    "        #get time right now, timezone should be correct if computer is synced properly\n",
    "          d = datetime.utcnow()\n",
    "          diff_time = datetime.utcnow() - timedelta(days = 1)\n",
    "\n",
    "\n",
    "          #time_now\n",
    "          # Make sure to URL-encode all parameters\n",
    "\n",
    "        #turn current time into a bunch of strings that we can add together to form link parameters below\n",
    "          year,month,day,hour,minute,second = str(d.year),str(d.month),str(d.day),str(d.hour),str(d.minute),str(d.second)\n",
    "          year_diff,month_diff,day_diff,hour_diff,minute_diff,second_diff = str(diff_time.year),str(diff_time.month),str(diff_time.day),str(diff_time.hour),str(diff_time.minute),str(diff_time.second)\n",
    "\n",
    "        #if any of our dates/times are only one digit, we add a '0' to the front to make them suitable for URL \n",
    "          if len(day) == 1:\n",
    "                day = '0'+ day\n",
    "          if len(month) == 1:\n",
    "                month = '0'+ month\n",
    "          if len(hour) == 1:\n",
    "                hour = '0' + hour\n",
    "          if len(minute) == 1:\n",
    "                minute = '0' + minute\n",
    "          if len(second) == 1:\n",
    "                second = '0' + second\n",
    "\n",
    "          if len(day_diff) == 1:\n",
    "                day_diff = '0'+ day_diff\n",
    "          if len(month_diff) == 1:\n",
    "                month_diff = '0'+ month_diff\n",
    "         #####there is a problem here with the days, I think it's when the next day is being called because UTC\n",
    "          parameters = urllib.urlencode({'begin_time': year_diff + '-' + month_diff + '-' + day_diff + 'T05:00:00',\n",
    "                                         'end_time': year + '-' + month + '-' + day + 'T05:00:00'})\n",
    "          payments = []\n",
    "          # For each location...\n",
    "          for location_id in location_ids:\n",
    "\n",
    "            #print 'Downloading payments for location with ID ' + location_id + '...'\n",
    "\n",
    "            request_path = '/v1/' + location_id + '/payments?' + parameters\n",
    "            more_results = True\n",
    "\n",
    "            # ...as long as there are more payments to download from the location...\n",
    "            while more_results:\n",
    "\n",
    "              # ...send a GET request to /v1/LOCATION_ID/payments\n",
    "              connection.request('GET', request_path, '', request_headers)\n",
    "              response = connection.getresponse()\n",
    "\n",
    "              # Read the response body JSON into the cumulative list of results\n",
    "              payments = payments + json.loads(response.read())\n",
    "\n",
    "              # Check whether pagination information is included in a response header, indicating more results\n",
    "              pagination_header = response.getheader('link', '')\n",
    "              if \"rel='next'\" not in pagination_header:\n",
    "                more_results = False\n",
    "              else:\n",
    "\n",
    "                # Extract the next batch URL from the header.\n",
    "                #\n",
    "                # Pagination headers have the following format:\n",
    "                # <https://connect.squareup.com/v1/LOCATION_ID/payments?batch_token=BATCH_TOKEN>;rel='next'\n",
    "                # This line extracts the URL from the angle brackets surrounding it.\n",
    "                next_batch_url = urlparse(pagination_header.split('<')[1].split('>')[0])\n",
    "\n",
    "                request_path = next_batch_url.path + '?' + next_batch_url.query\n",
    "\n",
    "          # Remove potential duplicate values from the list of payments\n",
    "          seen_payment_ids = set()\n",
    "          unique_payments = []\n",
    "          loc_data = []\n",
    "          for payment in payments:\n",
    "            if payment['id'] in seen_payment_ids:\n",
    "              continue\n",
    "            seen_payment_ids.add(payment['id'])\n",
    "            unique_payments.append(payment)\n",
    "            loc_data.append(unique_payments)\n",
    "          return loc_data\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "      # Get all payments from all of the business's locations\n",
    "      payments = get_payments_day(get_location_ids())\n",
    "      locs = [str(loc) for loc in get_location_ids()]\n",
    "      pay_data = payments\n",
    "    \n",
    "      # Print a sales summary report of the payments\n",
    "      #print_sales_report(payments)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #making empty lists to fill with JSON pulled data\n",
    "    name_list = []\n",
    "    quant_list = []\n",
    "    quant_id_list = []\n",
    "    time_list = []\n",
    "    location_list = []\n",
    "    #pulling in item name,quantity purchased for the day, id of item, and time of purchase\n",
    "    for n in range(len(pay_data)):\n",
    "        for i in pay_data[n]:\n",
    "            #all of our entries should be complete every time, if not, we'll add a nan\n",
    "            try:\n",
    "                name_list.append(i['itemizations'][n]['name'])\n",
    "            except:\n",
    "                name_list.append(np.nan)\n",
    "            try:\n",
    "                quant_list.append(str(i['itemizations'][n]['quantity']))\n",
    "            except:\n",
    "                quant_list.append(0)\n",
    "            try:\n",
    "                quant_id_list.append(i['itemizations'][n]['item_detail']['item_id'])\n",
    "            except:\n",
    "                quant_id_list.append(np.nan)\n",
    "            try:\n",
    "                time_list.append(i['created_at'])\n",
    "            except:\n",
    "                time_list.append(np.nan)\n",
    "            try:\n",
    "                location_list.append(i['merchant_id'])\n",
    "            except:\n",
    "                location_list.append('')\n",
    "    # In addition to an Authorization header, requests to the Connect API should\n",
    "    # include the indicated Accept and Content-Type headers.\n",
    "    request_headers = {'Authorization': 'Bearer ' + access_token,\n",
    "                   'Accept':        'application/json',\n",
    "                   'Content-Type':  'application/json'}\n",
    "\n",
    "    # Send a GET request to the ListLocations endpoint and obtain the response.\n",
    "    connection = httplib.HTTPSConnection('connect.squareup.com')\n",
    "    request_path = '/v1/'+locs[0]+'/items'\n",
    "    connection.request('GET', request_path, '', request_headers)\n",
    "    response = connection.getresponse()\n",
    "\n",
    "\n",
    "\n",
    "    # Convert the returned JSON body into an array of locations you can work with.\n",
    "    items_data = json.loads(response.read())\n",
    "\n",
    "\n",
    "    id_list = []\n",
    "    url_list = []\n",
    "    names_list = []\n",
    "    price_list = []\n",
    "    #pulling in item, id, price of item, and image url\n",
    "\n",
    "    for m in items_data:\n",
    "        #try and pull in data, if it doesn't exist for the instance, add a nan to be handled later\n",
    "        try:      \n",
    "            names_list.append(m['name'])\n",
    "            \n",
    "        except:\n",
    "            names_list.append(np.nan)\n",
    "        try:\n",
    "            id_list.append(m['id'])\n",
    "        except:\n",
    "            id_list.append(np.nan)\n",
    "        try:\n",
    "            url_list.append(m['master_image']['url'])\n",
    "        except:\n",
    "            url_list.append(np.nan)\n",
    "        try:\n",
    "            price_list.append(m['variations'][0]['price_money']['amount'])\n",
    "        except:\n",
    "            price_list.append(np.nan)\n",
    "    #make a dataframe of all of the item data\n",
    "    item_df = pd.DataFrame({'id':id_list,'url':url_list, 'name':names_list, 'price':price_list})\n",
    "    #make a dataframe of all the payment data\n",
    "    pay_df = pd.DataFrame({'quantity':quant_list,'id':quant_id_list,'item_name':name_list,'time_of_sale':time_list,'location':location_list})\n",
    "    #drop entries that are missing item_name and quantity\n",
    "    pay_df.dropna(subset = ['item_name','quantity']).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    item_df.price=item_df.price/100\n",
    "    \n",
    "    #this will allow us to merge price on later\n",
    "    price_df = item_df[['name','price']]\n",
    "    #merge item and payment data\n",
    "    fin_df = item_df.merge(pay_df, left_on = 'name', right_on= 'item_name')\n",
    "\n",
    "    #make quantity a numeric so we can do math with it\n",
    "    fin_df.quantity = pd.to_numeric(fin_df.quantity)\n",
    "    #isolate name, quantity, and location\n",
    "    revenue_df = fin_df.loc[:,['name','quantity','location']]\n",
    "    \n",
    "    #group up name of item, then group by locations within names\n",
    "    revenue_df = revenue_df.groupby(['name','location']).sum()\n",
    "    revenue_df = revenue_df.reset_index()\n",
    "    #merge with price dataframe to bring in price of each item\n",
    "    revenue_df = revenue_df.merge(price_df, on = 'name')\n",
    "    #multiply price by quantity to get revenue per product\n",
    "    revenue_df['revenue'] = revenue_df.quantity * revenue_df.price\n",
    "    #isolate just location and revenue\n",
    "    revenue_df = revenue_df[['location','revenue']]\n",
    "    #group up revenue by sum for each location\n",
    "    revenue_df = revenue_df.groupby('location').sum()\n",
    "    revenue_df = revenue_df.reset_index()\n",
    "    #convert revenue dataframe to a dictionary so we can add it to the mongo\n",
    "    rev_dict = revenue_df.to_dict(orient = 'list')\n",
    "    \n",
    "\n",
    "    try:#for dict_ in rev_dict_list:\n",
    "        for i,key in enumerate(rev_dict):\n",
    "            record.update_many({\n",
    "              'merchant_uid': MERCHANT_ID\n",
    "            },{\n",
    "              '$set': \n",
    "                  {'Location_revenues':{rev_dict['location'][i]:rev_dict['revenue']}\n",
    "                  }\n",
    "            }, upsert=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rev_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
